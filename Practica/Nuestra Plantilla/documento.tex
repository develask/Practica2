\documentclass[a4paper,10pt]{article}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsthm}
%\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{array}
\usepackage[round]{natbib}
\usepackage{array}
\theoremstyle{plain}
\usepackage{color}
\newtheorem{theo}{Theorem}
\newtheorem{defn}{Definition}

% Redefinimos la funcion \today para ponerla en castellano
\def\today{\number\day~de\space\ifcase\month\or 
  enero\or febrero\or marzo\or abril\or mayo\or junio\or 
  julio\or agosto\or septiembre\or octubre\or noviembre\or diciembre\fi 
  \space de~\number\year}
  
\begin{document}
\author{Mikel de Velasco}
\pagenumbering{roman}
\title{Pr\'actica 2}

\author{Mikel de Velasco, Ieltzu Irazu, Mï¿½ In\'es Fernandez}
\date{\today}
\maketitle

%\begin{abstract}
%In this manuscript, we study the Boltzmann distribution associated to the linear ordering problem. Particularly, we demonstrate that this distribution is L-decomposable. Moreover, we investigate towards an efficient sampling method of the Boltzmann distribution.
%\end{abstract}


\section{Introducci\'on}

Se pide diseÃ±ar un clasificador que implemente el m\'etodo k-NN b\'asico con la distancia de
Minkowski seg\'un la expresi\'on (\ref{minkowski}) donde {\color[rgb]{1,.5,0} n} representa el n\'umero de atributos empleados para caracterizar las muestras.

\begin{equation}\label{minkowski}
d(a,b)=\left[\sum_{i=1}^{{\color[rgb]{1,.5,0} n}}|a_{i}-b_{i}|^{\color{magenta} m}\right]^{\frac{1}{\color{magenta} m}}
\end{equation}

El clasificador permitir\'a seleccionar tanto el n\'umero de vecinos a explorar ({\color{blue} k}) como el par\'ametro {\color{magenta} m} de la expresi\'on (\ref{minkowski}). Elegir el lenguaje de programaci\'on que se considere m\'as apropiado para el diseÃ±o.
Para inferir el clasificador se dispone de un conjunto de datos (Diabetes.arff). El conjunto de datos dispone de 768 instancias para inferir el modelo. Para describir las instancias se utilizan 8 atributos m\'as la clase. Los atributos son los siguientes:

\begin{itemize}
\item Number of times pregnant
\item Plasma glucose concentration a 2 hours in an oral glucose tolerance test
\item Diastolic blood pressure 
\item Triceps skin fold thickness 
\item 2-Hour serum insulin 
\item Body mass index 
\item Diabetes pedigree function
\item Age 
\item Class variable 
\end{itemize}

La clase que hay que determinar es si el paciente tiene diabetes o no.

\subsection{Par\'ametro {\color{blue}k}}

El parametro {\color{blue}k} es el parametro que utilizaremos para indicar cuantos vecinos vamos a usar para evaluar el clasificador.

\subsection{Par\'ametro {\color{magenta}m}}

El parametro {\color{magenta}m} sera el parametro que utilizaremos para saber que distancia tenemos que utilizar para evaluar nuestro clasificador.
En esta pr\'actica hemos implementado 3 distintas distancias:
\begin{enumerate}
    \item Distancia de \textbf{Manhattan}:
    	
	La distanciade Manhattan (\ref{manhattan}), entre dos vectores ${\mathbf{x}}$, ${\mathbf{y}}$ en un espacio vectorial real n-dimensional con un sistema de Coordenadas cartesianas fijo es la suma de las longitudes de las proyecciones del segmento de línea entre los puntos sobre el sistema de ejes coordenados.

	\begin{equation}\label{manhattan}
	d(\mathbf{x},\mathbf{y})=\sum_{i=1}^{n}|x_{i}-y_{i}|
	\end{equation}
	
	Donde ${n}$ es el n\'umero de dimensiones.
    
    \item Distancia \textbf{Eucl\'idea}: 
    
    Un espacio eucl\'ideo es un espacio vectorial normado sobre los números reales de dimensión finita, en que la norma es la asociada al producto escalar ordinario. Para cada número entero no negativo n, el espacio eucl\'ideo n-dimensional se representa por el símbolo ${\mathbb{R}^{n}}$ y es el conjunto de todas las tuplas ordenadas ${(x_1,x_2,\ldots,x_n)}$ en donde cada ${x_i}$ es un n\'umero real, junto con la función distancia entre dos puntos ${(x1, \ldots, x_n) e (y1, \ldots, y_n)}$ definida por la fórmula:
    
    \begin{equation}\label{euclidea}
    d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\| = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
    \end{equation}
    
    Esta funci\'on distancia es una generalizaci\'on del teorema de Pit\'agoras y se denomina Distancia euclidiana (\ref{euclidea}).
    
    \item Distancia de \textbf{Minkowski}:
\end{enumerate}
    
\section{Metodolog\'ia}

En este apartado desarrollaremos nuestro propio algoritmo K-Nearest Neighbors y describiremos el dise\~no y c\'omo hemos implementado este algoritmo. Adem\'as haremos una breve descripci\'on de como hacer funcionar el programa.

El algoritmo que hemos desarrollado es b\'asicamente una adaptaci\'on del clasificador IBk ya que hemos cogido su c\'odigo y le hemos cambiado la forma de estimar que estaban utilizando. 


Nuestro programa puede ser ejecutado desde eclipse de una manera muy f\'acil. Si ejecutas el Probador.java conseguiras una ejecuci\'on total del programa y obtendras los resultados en la carpeta de ficheros. Por otro lado, tambi\'en se pueden ejecutar de forma individual. Se diferenciarian 3 ejecuciones diferentes. Preprocesador.java nos sirve para quitar todo lo malo que venga en los datos(Extreme values, outliers,...).

	Como parametros de entrada tendremos los siguientes

Despu\'es ejecutariamos Modelo.java y con ello conseguiriamos obtener los dos modelos de los que estamos tratando en la practica. 

	Como parametros de entrada tendremos los siguientes


Por ultimo, ejecutariamos el Clasificador.java y con ello conseguiriamos los resultados que necesitamos para comparar los modelos anteriores. 

	Como parametros de entrada tendremos los siguientes


\section{Resultados}

En esta seccion mostraremos los resultados que hemos obtenido de las ejecuciones anteriores

\section{Conclusiones}

Realizar un clasificador desde cero ha sido una tarea complicada a que nos hemos basado en el modelo del IBk, y le hemos ajustado el pseudoc\'odigo que ten\'iamos. Ha sido una tarea entretenida y muy din\'amica pero muy costosa. Como conclusi\'on tenemos que decir que no merece la pena crear un modelo propio habiendo ya el IBk.   

\section{Valoraci\'on Subjetiva}
Una vez finalizado todo el proyecto, cada uno hemos echo una valoraci\'on de todo lo que ha supuesto el proyecto individualmente.

\textbf{Ieltzu:} Personalmente ha sido una tarea que no me ha gustado mucho. He visto inecesaria la practica y para lo \'unico que me ha servido es para darme cuenta de lo dif\'icil que es implementar un clasificador propio. 

\textbf{Mikel:} Bajo mi prespect\'iva, esta pr\'actica, ha ayudado a comprender como funciona el algoritmo k-NN con los diferentes p\'arametros pasados. Sabiendo que alcanzar la eficiencia del algoritmo ya implementado por weka es dif\'icil (ya que este ha sido testeado y comprobado por numerosos investigadores) es un buen método para aprender a utilizar herramientas que est\'an bien testeadas ademas de comprender por dentro como funcionan dichas herramientas intentando implementarlas nosotros.

\textbf{Maria:}



\bibliographystyle{plainnat}
\bibliography{./bibliography.bib}

\end{document}

